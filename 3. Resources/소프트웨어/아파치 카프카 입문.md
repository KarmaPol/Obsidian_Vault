### Before Kafka
source application - target application 관계가 많아질 수록
유지 보수가 매우 어려워지고, 장애에 대처하기 어렵다
### Features
아주 유연한 큐 역할
고 가용성, 낮은 지연과 고가용성
- 컨슈머
- 토픽
- 프로듀서
## 토픽
데이터가 들어가는 공간
하나의 토픽은 여러개의 파티션으로 구성
- 파티션
  큐와 비슷하게 데이터가 차곡차곡 쌓임
  컨슈머는 오래된 순으로 데이터를 가져옴
  -> 이때 consumer가 record를 가져가더라도 데이터는 삭제되지 않음
  => 삭제되지 않으므로 동일 데이터를 2번 이상 처리할 수 있음
#### 파티션이 여러개일때
- 키가 null일 경우
  라운드 로빈으로 파티션 결정
- 키가 있고 기본 파티셔너를 사용할 경우
  키의 해시값으로 특정 파티션에 할당

파티션을 늘리면 데이터를 분산 처리 가능
-> 이때 파티션을 늘릴 수 있지만 줄일 수는 없음
레코드의 보관 기간은 설정 가능
## Broker
카프카가 설치되어있는 서버
일반적으로 3개 이상의 브로커(서버)로 구성 권장
### Replication
파티션의 복제
replication = 2이라면, 원본 1개와 복제본 1개
replication = 3이라면, 원본 1개와 복제본 2개

고가용성을 위해 사용 -> Leader 서버 장애 발생시 Follwer 서버가 Leader
##### ACK
데이터를 보낸 뒤 응답값
ack = 0, 1 -> 데이터 유실을 확인하기 어렵지만 빠름
ack = all -> 데이터 유실은 없지만 속도가 느림
## 파티셔너
레코드를 토픽의 어떤 파티션에 넣을지 결정
기본 파티셔너 외에도 커스텀 파티셔너 지정 가능 -> 8개 파티션은 VIP, 2개 파티션은 일반고객
## 컨슈머 랙
프로듀서 넣은 offset - 컨슈머 가져간 offset = Kafka consumer lag
컨슈머가 성능이 좋지 않거나, 비정상 작동 시 랙이 커진다
### Burrow
Kafka Consumer Lag을 효율적으로 모니터링 할 수 있는 오픈 소스
## 이벤트 브로커 VS 메시지 브로커
1. 이벤트 브로커 - 카프카
   레코드를 보관하고, 인덱스를 통해 개별 엑세스 관리
   -> 장애 지점부터 재처리, 많은 양의 스트림 데이터 효과적 처리
   => 이벤트 기반 마이크로 서비스
2. 메시지 브로커 - 래빗엠큐
   메시지를 보내고 처리하고 나면 짧은 시간 내에 삭제
