- 대용량의 데이터를 병렬로 실행하게 해줌
# 아키텍처
- 드라이버 프로그램 (내 스크립트, Spark context)
- 클러스터 매니저(Spark, 하둡 기반 등)
- Executor 노드

- divide and conquer 전략으로 병렬화해 처리후 합치기
## 왜 빠르지?
- MapReduce(기존 하둡, 한가지 방식만) 보다 100배 빠름
- DAG 엔진은 메모리 기반으로 워크플로우를 자동 최적화
## 어떻게 쓸수있나?
- 스칼라, 파이썬 기반
- 주로 **SQL API**
	- RDD(lower level) 로 저수준 정의도 가능
# 스파크 구성요소
- Spark Core
- Spark Streaming
	- 실시간 에러 스트리밍 처리 등에 유용
	- 카프카에서 오는 이벤트를 스파크가 처리
- Spark SQL
	- **Spark를 거대한 SQL RDB로 생각할수 있게 해줌**
	- 수평 확장이 자유로움
	- 하지만 분산 서버간 Join 연산이 비효율적임
- GraphX
# 스칼라?
- 자바에 비해 쉽고 간결함
- 함수형 프로그래밍이 분산 서버에 적절함

```scala
val squared = nums.map(x=>x*x).collect()
```