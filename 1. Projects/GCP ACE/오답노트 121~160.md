Your managed instance group raised an alert stating that new instance creation has failed to create new instances. You need to maintain the number of running instances specified by the template to be able to process expected application traffic. What should you do?

A. Create an instance template that contains valid syntax which will be used by the instance group. Delete any persistent disks with the same name as instance names.

B. Create an instance template that contains valid syntax that will be used by the instance group. Verify that the instance name and persistent disk name values are not the same in the template.

C. Verify that the instance template being used by the instance group contains valid syntax. Delete any persistent disks with the same name as instance names. Set the disks.autoDelete property to true in the instance template.

D. Delete the current instance template and replace it with a new instance template. Verify that the instance name and persistent disk name values are not the same in the template. Set the disks.autoDelete property to true in the instance template.

정답 : A

사이트는 C가 정답이라고 하지만, 토론을 보면 D가 조금 더 우세함

사실 C도 정답인 것 같지만 새롭게 생성하는 것이 아니라서

인스턴스 템플릿을 업데이트할 수 없는 한계가 존재함

---
Your Dataproc cluster runs in a single Virtual Private Cloud (VPC) network in a single subnet with range 172.16.20.128/25. There are no private IP addresses available in the VPC network. You want to add new VMs to communicate with your cluster using the minimum number of steps. What should you do?

A. Modify the existing subnet range to 172.16.20.0/24.

B. Create a new Secondary IP Range in the VPC and configure the VMs to use that range.

C. Create a new VPC network for the VMs. Enable VPC Peering between the VMs' VPC network and the Dataproc cluster VPC network.

D. Create a new VPC network for the VMs with a subnet of 172.32.0.0/16. Enable VPC network Peering between the Dataproc VPC network and the VMs VPC network. Configure a custom Route exchange.


정답 : A

사이트는 C가 정답이라고 하지만 토론을 보면 A와 C가 분분하지만 A가 최소 방법

SUBNET의 IP 범위를 24로 확장하려면 다음과 같음

gcloud compute networks subnets expand-ip-range USBNET --region = REGION --prefix-length=24

참고로 서브넷을 확장할 수는 있지만 축소할 수는 없음

질문은 확장이기 때문에 가능하며 /25는 128개의 IP를 제공하지만, 24로 확장하면 256으로 증가함

---
You manage an App Engine Service that aggregates and visualizes data from BigQuery. The application is deployed with the default App Engine Service account.

The data that needs to be visualized resides in a different project managed by another team. You do not have access to this project, but you want your application to be able to read data from the BigQuery dataset. What should you do?

A. Ask the other team to grant your default App Engine Service account the role of BigQuery Job User.

B. Ask the other team to grant your default App Engine Service account the role of BigQuery Data Viewer.

C. In Cloud IAM of your project, ensure that the default App Engine service account has the role of BigQuery Data Viewer.

D. In Cloud IAM of your project, grant a newly created service account from the other team the role of BigQuery Job User in your project.


정답 : B

액세스에 필요한 리소스는 다른 프로젝트에 있으며

BigQuery 데이터 뷰어 역할에 적절한 설명임

참고로 작업 사용자 역할은 쿼리를 실행할 수 있는 권한은 있으나

데이터를 읽을 수 있는 권한은 부여하지 않음

---
Your company runs one batch process in an on-premises server that takes around 30 hours to complete. The task runs monthly, can be performed offline, and must be restarted if interrupted. You want to migrate this workload to the cloud while minimizing cost. What should you do?

A. Migrate the workload to a Compute Engine Preemptible VM.

B. Migrate the workload to a Google Kubernetes Engine cluster with Preemptible nodes.

C. Migrate the workload to a Compute Engine VM. Start and stop the instance as needed.

D. Create an Instance Template with Preemptible VMs On. Create a Managed Instance Group from the template and adjust Target CPU Utilization. Migrate the workload.

정답 : C

사이트는 B가 정답이라고 하지만, 토론을 보면 C가 많음

중단된 경우 다시 시작해야 돼서 선점형을 진행하지 않는 것으로 판단됨

또한, 선점형은 24시간 미만의 일괄 작업에 적합함

그리고 쿠버네티스 엔진은 비용 효율적인 솔루션이 아님

---
The core business of your company is to rent out construction equipment at a large scale. All the equipment that is being rented out has been equipped with multiple sensors that send event information every few seconds. These signals can vary from engine status, distance traveled, fuel level, and more. Customers are billed based on the consumption monitored by these sensors. You expect high throughput "" up to thousands of events per hour per device "" and need to retrieve consistent data based on the time of the event. Storing and retrieving individual signals should be atomic. What should you do?

A. Create a file in Cloud Storage per device and append new data to that file.

B. Create a file in Cloud Filestore per device and append new data to that file.

C. Ingest the data into Datastore. Store data in an entity group based on the device.

**D. Ingest the data into Cloud Bigtable. Create a row key based on the event timestamp.**


정답 : D

사이트는 C가 정답이라고 하지만 D가 압도적

BIG 및 Atomic에 필요한 것은 Cloud Bigtable

Datastore는 완전히 원자성이 아니며 Storage는 이벤트 시간을 기준으로 데이터를 내보낼 수 있는 옵션이 아님, Filestore는 파일 저장소라서 더욱 아님

---
Your company has workloads running on Compute Engine and on-premises. The Google Cloud Virtual Private Cloud (VPC) is connected to your WAN over a

Virtual Private Network (VPN). You need to deploy a new Compute Engine instance and ensure that no public Internet traffic can be routed to it. What should you do?

A. Create the instance without a public IP address.

B. Create the instance with Private Google Access enabled.

C. Create a deny-all egress firewall rule on the VPC network.

D. Create a route on the VPC to route all traffic to the instance over the VPN tunnel.

​

정답 : A

사이트는 B가 답이라고 하지만 토론은 A가 압도적

B는 내부 통신을 허용하지만 공용 트래픽을 제한하지 않음

C는 모두 거부하는 것이 좋지만 송신을 위한 것 (Ingress로 해야 함)

D는 퍼블릭 인터넷 트래픽이 인스턴스에 도달하는 것을 방지하는 문제를 해결하지 못함

---
Your existing application running in Google Kubernetes Engine (GKE) consists of multiple pods running on four GKE n1""standard""2 nodes. You need to deploy additional pods requiring n2""highmem""16 nodes without any downtime. What should you do?

A. Use gcloud container clusters upgrade. Deploy the new services.

B. Create a new Node Pool and specify machine type n2""highmem""16. Deploy the new pods.

C. Create a new cluster with n2""highmem""16 nodes. Redeploy the pods and delete the old cluster.

D. Create a new cluster with both n1""standard""2 and n2""highmem""16 nodes. Redeploy the pods and delete the old cluster.

---
You have an application that uses Cloud Spanner as a database backend to keep current state information about users. Cloud Bigtable logs all events triggered by users. You export Cloud Spanner data to Cloud Storage during daily backups. One of your analysts asks you to join data from Cloud Spanner and Cloud

Bigtable for specific users. You want to complete this ad hoc request as efficiently as possible. What should you do?

A. Create a dataflow job that copies data from Cloud Bigtable and Cloud Storage for specific users.

B. Create a dataflow job that copies data from Cloud Bigtable and Cloud Spanner for specific users.

C. Create a Cloud Dataproc cluster that runs a Spark job to extract data from Cloud Bigtable and Cloud Storage for specific users.

D. Create two separate BigQuery external tables on Cloud Storage and Cloud Bigtable. Use the BigQuery console to join these tables through user fields, and apply appropriate filters.
​

정답 : D

사이트는 B가 정답이라고 하지만 토론을 보면 D가 압도적

BigQuery는 Cloud Bigtable, Cloud Storage, Google Drive, Cloud SQL에 대해서

직접 데이터 쿼리가 가능함

B의 경우는 대응만 하고 Join 처리에 대한 내용이 없음

---
A colleague handed over a Google Cloud Platform project for you to maintain. As part of a security checkup, you want to review who has been granted the Project

Owner role. What should you do?

A. In the console, validate which SSH keys have been stored as project-wide keys.

B. Navigate to Identity-Aware Proxy and check the permissions for these resources.

C. Enable Audit Logs on the IAM & admin page for all resources, and validate the results.

D. Use the command gcloud projects get""iam""policy to view the current role assignments.

정답 : D

사이트는 A가 정답이라고 하지만 토론을 보면 D가 압도적

gcloud projects get ""iam ""policy 명령어를 사용하여 현재 역할 할당 확인이 가능함

---

You have a batch workload that runs every night and uses a large number of virtual machines (VMs). It is fault-tolerant and can tolerate some of the VMs being terminated. The current cost of VMs is too high. What should you do?

A. Run a test using simulated maintenance events. If the test is successful, use preemptible N1 Standard VMs when running future jobs.

B. Run a test using simulated maintenance events. If the test is successful, use N1 Standard VMs when running future jobs.

C. Run a test using a managed instance group. If the test is successful, use N1 Standard VMs in the managed instance group when running future jobs.

D. Run a test using N1 standard VMs instead of N2. If the test is successful, use N1 Standard VMs when running future jobs.

정답 : A

사이트는 B가 정답이라고 하지만 토론을 보면 A가 압도적

우선 선점형(preemptible) 인스턴스는 일반 인스턴스보다 훨씬 저렴한 가격으로 만들고 실행 가능

선점형 인스턴스는 인스턴스 선점을 견딜 수 있는 내 결함성 애플리케이션에만 권장함

---

Your company runs its Linux workloads on Compute Engine instances. Your company will be working with a new operations partner that does not use Google

Accounts. You need to grant access to the instances to your operations partner so they can maintain the installed tooling. What should you do?

A. Enable Cloud IAP for the Compute Engine instances, and add the operations partner as a Cloud IAP Tunnel User.

B. Tag all the instances with the same network tag. Create a firewall rule in the VPC to grant TCP access on port 22 for traffic from the operations partner to instances with the network tag.

C. Set up Cloud VPN between your Google Cloud VPC and the internal network of the operations partner.

D. Ask the operations partner to generate SSH key pairs, and add the public keys to the VM instances.
​

정답 : A

사이트는 B가 정답이라고 하지만, 토론을 보면 A가 압도적

IAP를 사용하면 SSH가 외부 ID로 인스턴스를 계산할 수 있으며

IAP를 사용하면 HTTPS로 액세스 되는 애플리케이션에 대한 중앙 인증 계층을 설정할 수 있어

네트워크 수준 방화벽에 의존하는 대신 애플리케이션 수준 액세스 제어 모델 사용 가능

단, IAP를 사용하기 위해서 구글 계정이 필요하다는 의견들이 있어서 헷갈림


---
You have been asked to set up Object Lifecycle Management for objects stored in storage buckets. The objects are written once and accessed frequently for 30 days. After 30 days, the objects are not read again unless there is a special need. The object should be kept for three years, and you need to minimize cost. What should you do?

A. Set up a policy that uses Nearline storage for 30 days and then moves to Archive storage for three years.

B. Set up a policy that uses Standard storage for 30 days and then moves to Archive storage for three years.

C. Set up a policy that uses Nearline storage for 30 days, then moves the Coldline for one year, and then moves to Archive storage for two years.

D. Set up a policy that uses Standard storage for 30 days, then moves to Coldline for one year, and then moves to Archive storage for two years.

정답 : B

사이트는 A가 정답이라고 하지만 토론을 보면 의견이 분분함. 본인은 B라고 생각됨

자주 액세스 되기 때문에 Nearline 스토리지는 아니라고 생각됨,

특히 Nearline 스토리지는 액 세스 당 지불이 필요함

또한 아카이브 스토리지는 1년에 한번 미만으로 액세스하는 데이터 가장 적합하며

Coldline 스토리지보다 저렴함