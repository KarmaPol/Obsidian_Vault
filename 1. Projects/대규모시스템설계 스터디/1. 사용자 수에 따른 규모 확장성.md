## 단일서버
웹, 앱, DB, 캐시 등이 전부 서버 한대
- 사용자 요청 처리 흐름
	1. 사용자는 도메인 이름을 이용하여 웹사이트에 접속, DNS 서버에 변환 요청
	2. IP 주소 반환
	3. 해당 IP주소에 HTTP 요청 전달
	4. 요청 받은 웹 서버는 HTML페이지나 JSON 응답 반환
## DB 서버
웹/모바일 트래픽 처리 서버(웹 계층), 데이터베이스 서버(데이터 계층) 분리
### NoSQL을 고려해야할때
아주 낮은 latency 요구
데이터가 비정형, 데이터를 직렬화하거나 역직렬화할 수 있기만 하면됨
아주 많은 양의 데이터를 저장할 필요가 있음
## 스케일업 vs 스케일아웃
트래픽의 양이 적을 때는 수직적 확장이 좋다 (단순하다)
하지만
- 결국 CPU, 메모리를 무한정 증설할 수는 없다
- 서버에 장애가 발생하면 웹/앱은 중단된다

따라서 대규모 시스템엔 **스케일 아웃**이 더 적절하고
**부하 분산기, 로드 밸런서**를 도입하는 것이 좋다.
### 로드 밸런서
웹 서버들에게 트래픽을 고르게 분산
**public ip -> 로드 밸런서 -> private ip1, private ip2**

- 서버1이 다운되면 모든 트래픽은 서버2로 전송
- 트래픽이 가파르게 증가하면 웹 서버만 추가해주면 된다. 로드 밸런서가 자동으로 분산
### DB 다중화
master-slave 서버 설정
데이터 원본은 master, 사본은 slave에 저장
write 연산은 master에서만 지원
#### 장점
- 더 나은 성능
- 안정성
- 가용성

- 부 서버가 다운 -> 주 서버(부 서버가 1대일때), 다른 부 서버가 장애 서버 대체
- 주 서버가 다운 -> 부 서버가 새로운 주 서버
  이때 부 서버 데이터가 최신 상태가 아닐 수 있기 때문에 **복구 스크립트**를 돌려 데이터 추가해야함
## 캐시
값 비싼 연산결과, 자주 참조되는 데이터를 메모리 안에 두고, 요청이 빨리 처리되게 하는 저장소
캐시 계층은 DB보다 훨씬 빠르고, DB의 부하를 줄일 수 있다
#### 캐시 사용 시 유의할 점
- 데이터 갱신은 적고, 참조는 빈번하면 캐시 사용이 유리하다
- 캐시는 휘발성이므로 중요 데이터는 지속적 저장소에 두어야한다
- 캐시 만료 정책이 너무 길면 원본과 차이가 나고, 너무 짧으면 DB를 자주 읽게 된다
- 원본과 캐시 내 사본의 일관성을 어떻게 유지해야 하는가
- 캐시 서버를 한대만 두면 단일장애지점(SPOF, *특점 지점의 장애가 전체 시스템 동작 중단*)이 될 수 있다
  => 여러 지역에 캐시 서버 분산
- 캐시 메모리 크기가 너무 작으면 데이터가 너무 자주 밀려나가 성능이 저하된다 => 캐시 메모리 과할당
- 캐시 데이터 방출 정책
	- LRU(Least Recently Used) 마지막으로 사용된 시점이 가장 오래된 데이터 방출
	- LFU(Least Frequently Used) 사용된 빈도가 가장 낮은 데이터 방출
	- FIFO(First In First Out) 데이터 선입선출
## CDN
정적 콘텐츠를 전송하는데 쓰이는 지리적으로 분산된 서버의 네트워크
이미지, 비디오, JavaScript 파일 등 캐시
#### CDN 사용 시 고려해야 할 사항
- 비용
  자주 사용되지 않는 컨텐츠를 캐싱하는 것은 이득이 크지 않다
- 적절한 만료 시한
  너무 길면 컨첸츠 신선도 저하, 너무 짧으면 원본 서버에 너무 빈번히 접속
- CDN 장애 대처 방안
  CDN 서버 장애시 원본 서버로부터 직접 컨텐츠 가져오도록 클라이언트 구성
## Stateless 웹 계층
http 요청 마다 사용자 세션 정보를 각 서버에 따로 저장하면,
같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야한다
-> 로드 밸런서에 부담, 서버를 추가하거나 제거하기도 까다로워진다
### 무상태 아키텍처
웹 서버와 사용자 상태 정보 저장소를 분리한다
=> 단순하고, 안정적이며, 규모 확장이 쉽다
RDB, 캐시 시스템, NoSQL 모두 사용할 수 있지만 NoSQL이 규모 확장이 간편하다
## 데이터 센터
사용자는 로드밸런서에 의해 가장 가까운 데이터 센터로 안내 -> 지리적 라우팅(geoDNS-routing)
만약 데이터 센터2에 장애가 발생하면 데이터 센터1로 모든 트래픽 전송
#### 기술적 난제
- 트래픽 우회
  사용자에 가장 가까운 데이터 센터로 트래픽을 보내줘야한다
- 데이터 동기화
  여러 데이터 센터에 걸쳐 DB 다중화
- 테스트와 배포
  모든 데이터 센터에 동일한 테스트
## 메시지 큐
비동기 통신 지원 컴포넌트
생산자가 메시지를 만들어 메시지 큐에 발행,
소비자는 메시지를 받아 그에 맞는 동작 수행
**웹 서버 - 메시지 큐 - 작업 서버**

메시지 큐 이용시 서버 간 결합이 느슨해져서 확장성에 이점
(ex. 시간이 오래 걸리는 사진 보정 작업을 비동기적으로 완료)
## 로그, 메트릭, 자동화
대규모 서비스의 경우엔 필수적
- 로그
  에러 로그를 단일 서비스로 모아주는 도구를 활용하면 더 쉽게 모니터링 가능
- 메트릭
  사업 현황, 시스템 현재 상태를 손쉽게 파악 가능
  - 호스트 단위 메트릭 : CPU, 메모리, 디스크 I/O
  - 종합 메트릭 : DB 계층 성능, 캐시 계층 성능
  - 핵심 비즈니스 메트릭 : 일별 능동 사용자, 수익, 재방문
- 자동화
  CI, CD를 도와주는 도구를 활용하면 자동으로 검증, 빌드, 테스트, 배포 가능 -> 생산성 크게 향상
## DB의 규모 확장
### 스케일 업
무한 증설은 불가능하다
SPOF 위험성이 크다
비용이 많이 든다
### 스케일 아웃
sharding
DB를 shard라고 부르는 작은 단위로 분할
Shard에 보관되는 데이터 사이에는 중복 X
샤딩키(ex. userid)를 적절히 지정해데이터를 고르게 분할해야한다
#### 샤딩의 문제점
- 데이터의 재 샤딩
  샤드가 전부 소진됐거나, 데이터 분포가 균등하지 못할 경우,
  샤드 키를 계산하는 함수를 변경하고 데이터를 재배치해야한다
- 유명인사 문제
  특정 샤드에 질의가 집중되어 서버에 과부하
  -> 유명인사 각각에 샤드를 할당하거나, 더 쪼갠다
- 조인과 비정규화
  여러 샤드에 걸친 데이터를 조인하기가 힘들다
  -> 비정규화로 애초에 조인이 필요없게 한다


