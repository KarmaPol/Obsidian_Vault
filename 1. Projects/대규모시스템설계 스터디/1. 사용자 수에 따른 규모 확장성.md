## 단일서버
웹, 앱, DB, 캐시 등이 전부 서버 한대
- 사용자 요청 처리 흐름
	1. 사용자는 도메인 이름을 이용하여 웹사이트에 접속, DNS 서버에 변환 요청
	2. IP 주소 반환
	3. 해당 IP주소에 HTTP 요청 전달
	4. 요청 받은 웹 서버는 HTML페이지나 JSON 응답 반환
## DB 서버
웹/모바일 트래픽 처리 서버(웹 계층), 데이터베이스 서버(데이터 계층) 분리
### NoSQL을 고려해야할때
아주 낮은 latency 요구
데이터가 비정형, 데이터를 직렬화하거나 역직렬화할 수 있기만 하면됨
아주 많은 양의 데이터를 저장할 필요가 있음
## 스케일업 vs 스케일아웃
트래픽의 양이 적을 때는 수직적 확장이 좋다 (단순하다)
하지만
- 결국 CPU, 메모리를 무한정 증설할 수는 없다
- 서버에 장애가 발생하면 웹/앱은 중단된다

따라서 대규모 시스템엔 **스케일 아웃**이 더 적절하고
**부하 분산기, 로드 밸런서**를 도입하는 것이 좋다.
### 로드 밸런서
웹 서버들에게 트래픽을 고르게 분산
**public ip -> 로드 밸런서 -> private ip1, private ip2**

- 서버1이 다운되면 모든 트래픽은 서버2로 전송
- 트래픽이 가파르게 증가하면 웹 서버만 추가해주면 된다. 로드 밸런서가 자동으로 분산
### DB 다중화
master-slave 서버 설정
데이터 원본은 master, 사본은 slave에 저장
write 연산은 master에서만 지원
#### 장점
- 더 나은 성능
- 안정성
- 가용성

- 부 서버가 다운 -> 주 서버(부 서버가 1대일때), 다른 부 서버가 장애 서버 대체
- 주 서버가 다운 -> 부 서버가 새로운 주 서버
  이때 부 서버 데이터가 최신 상태가 아닐 수 있기 때문에 **복구 스크립트**를 돌려 데이터 추가해야함
## 캐시
값 비싼 연산결과, 자주 참조되는 데이터를 메모리 안에 두고, 요청이 빨리 처리되게 하는 저장소
캐시 계층은 DB보다 훨씬 빠르고, DB의 부하를 줄일 수 있다
#### 캐시 사용 시 유의할 점
- 데이터 갱신은 적고, 참조는 빈번하면 캐시 사용이 유리하다
- 캐시는 휘발성이므로 중요 데이터는 지속적 저장소에 두어야한다
- 캐시 만료 정책이 너무 길면 원본과 차이가 나고, 너무 짧으면 DB를 자주 읽게 된다
- 원본과 캐시 내 사본의 일관성을 어떻게 유지해야 하는가
- 캐시 서버를 한대만 두면 단일장애지점(SPOF, *특점 지점의 장애가 전체 시스템 동작 중단*)이 될 수 있다
  => 여러 지역에 캐시 서버 분산
- 캐시 메모리 크기가 너무 작으면 데이터가 너무 자주 밀려나가 성능이 저하된다 => 캐시 메모리 과할당
- 캐시 데이터 방출 정책
	- LRU(Least Recently Used) 마지막으로 사용된 시점이 가장 오래된 데이터 방출
	- LFU(Least Frequently Used) 사용된 빈도가 가장 낮은 데이터 방출
	- FIFO(First In First Out) 데이터 선입선출
## CDN
정적 콘텐츠를 전송하는데 쓰이는 지리적으로 분산된 서버의 네트워크
이미지, 비디오, JavaScript 파일 등 캐시
#### CDN 사용 시 고려해야 할 사항
- 비용
  자주 사용되지 않는 컨텐츠를 캐싱하는 것은 이득이 크지 않다
- 적절한 만료 시한
  너무 길면 컨첸츠 신선도 저하, 너무 짧으면 원본 서버에 너무 빈번히 접속
- CDN 장애 대처 방안
  CDN 서버 장애시 원본 서버로부터 직접 컨텐츠 가져오도록 클라이언트 구성
## Stateless 웹 계층
http 요청 마다 사용자 세션 정보를 각 서버에 따로 저장하면,
같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야한다
-> 로드 밸런서에 부담, 서버를 추가하거나 제거하기도 까다로워진다
### 무상태 아키텍처
웹 서버와 사용자 상태 정보 저장소를 분리한다
=> 단순하고, 안정적이며, 규모 확장이 쉽다
RDB, 캐시 시스템, NoSQL 모두 사용할 수 있지만 NoSQL이 규모 확장이 간편하다
## 데이터 센터
